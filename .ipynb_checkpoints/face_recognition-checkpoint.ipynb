{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff6d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6abb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_FACES_DIR = \"knowned\"\n",
    "\n",
    "UNKNOWN_FACES_DIR = \"unknowed\"\n",
    "\n",
    "TOLERANCE = 0.6\n",
    "\n",
    "FRAME_THICKNESS = 3\n",
    "\n",
    "FONT_THICKNESS = 2\n",
    "\n",
    "MODEL =\"hog\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef68d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name wisdom\n",
      "Image Filename .trashed-1692256107-IMG_20230718_080818_649.jpg\n",
      "Image Filename IMG_20230620_103709_839.jpg\n",
      "Image Filename IMG_20230620_103744_991.jpg\n",
      "Image Filename IMG_20230620_103811_492.jpg\n",
      "Image Filename IMG_20230620_103812_775.jpg\n",
      "Image Filename Snapchat-1263372439.jpg\n",
      "Image Filename Snapchat-843564179.jpg\n"
     ]
    }
   ],
   "source": [
    "known_faces = []\n",
    "\n",
    "known_names = []\n",
    "\n",
    "\n",
    "for name in os.listdir(os.path.join(os.getcwd(), KNOWN_FACES_DIR)):\n",
    "    print(\"Name\", name)\n",
    "\n",
    "    for image_filename in os.listdir(os.path.join(os.getcwd(), f'{KNOWN_FACES_DIR}/{name}')):\n",
    "        \n",
    "        print(\"Image Filename\", image_filename)\n",
    "        \n",
    "        image = face_recognition.load_image_file(os.path.join(os.getcwd(), f'{KNOWN_FACES_DIR}/{name}/{image_filename}'))\n",
    "        \n",
    "        encoding = face_recognition.face_encodings(image, model=MODEL)[0]\n",
    "        \n",
    "        known_faces.append(encoding)\n",
    "        \n",
    "        known_names.append(name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6510faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_20230715_141519_521.jpg\n",
      "IMG_20230715_141523_214.jpg\n",
      "IMG_20230715_141524_780.jpg\n",
      "IMG_20230725_131823_094.jpg\n",
      "IMG_20230725_131829_405.jpg\n",
      "IMG_20230725_131831_801.jpg\n"
     ]
    }
   ],
   "source": [
    "for unknown_image_filename in os.listdir(os.path.join(os.getcwd(), UNKNOWN_FACES_DIR)):\n",
    "    print(unknown_image_filename)\n",
    "    \n",
    "    image = face_recognition.load_image_file(os.path.join(os.getcwd(), f'{UNKNOWN_FACES_DIR}/{unknown_image_filename}'))\n",
    "    \n",
    "    \n",
    "    locations = face_recognition.face_locations(image)\n",
    "    \n",
    "    encodings = face_recognition.face_encodings(image, locations, model=MODEL)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "        \n",
    "        results =face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        \n",
    "        match = None\n",
    "        \n",
    "        if True in results:\n",
    "            match = known_names[results.index(True)]\n",
    "            \n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2] + 22)\n",
    "            \n",
    "            color = [255, 0, 0]\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "            \n",
    "            \n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2] + 22)\n",
    "            \n",
    "            color = [255, 0, 0]\n",
    "            \n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            \n",
    "            cv2.putText(image, match, \n",
    "                        (face_location[3] + 10, face_location[2]+ 15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), \n",
    "                        FONT_THICKNESS)\n",
    "            \n",
    "    cv2.imshow(unknown_image_filename, image)\n",
    "    \n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    cv2.destroyWindow(unknown_image_filename)\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8c4eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for unknown_image_filename in os.listdir(os.path.join(os.getcwd(), UNKNOWN_FACES_DIR)):\n",
    "#     print(unknown_image_filename)\n",
    "    \n",
    "#     image = face_recognition.load_image_file(os.path.join(os.getcwd(), f'{UNKNOWN_FACES_DIR}/{unknown_image_filename}'))\n",
    "    \n",
    "    \n",
    "#     locations = face_recognition.face_locations(image)\n",
    "    \n",
    "#     encodings = face_recognition.face_encodings(image, locations, model=MODEL)\n",
    "    \n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "#     for face_encoding, face_location in zip(encodings, locations):\n",
    "        \n",
    "#         results =face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        \n",
    "#         match = None\n",
    "        \n",
    "#         if True in results:\n",
    "#             match = known_names[results.index(True)]\n",
    "            \n",
    "#             top_left = (face_location[3], face_location[0])\n",
    "#             bottom_right = (face_location[1], face_location[2] + 22)\n",
    "            \n",
    "#             color = [255, 0, 0]\n",
    "            \n",
    "#             cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "            \n",
    "            \n",
    "#             top_left = (face_location[3], face_location[0])\n",
    "#             bottom_right = (face_location[1], face_location[2] + 22)\n",
    "            \n",
    "#             color = [255, 0, 0]\n",
    "            \n",
    "#             cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            \n",
    "#             cv2.putText(image, match, \n",
    "#                         (face_location[3] + 10, face_location[2]+ 15), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), \n",
    "#                         FONT_THICKNESS)\n",
    "            \n",
    "#     cv2.imshow(unknown_image_filename, image)\n",
    "    \n",
    "    \n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "#     cv2.destroyWindow(unknown_image_filename)\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64227c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
